import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.functions;
import org.apache.spark.sql.streaming.StreamingQuery;
import org.apache.spark.sql.streaming.StreamingQueryException;

import java.util.concurrent.TimeoutException;

// Illegal reflective access warnings caused by using Java 11 with Spark, ignore for now
public class SparkKafkaConsumer {

    public static void main(String[] args) {
        SparkSession spark = SparkSession
                .builder()
                .appName("SparkKafkaConsumer")
                .master("local[*]") // Use all available cores
                .getOrCreate();

        // Kafka parameters
        String kafkaBootstrapServers = "localhost:65357";  // Replace with your Kafka broker(s)
        String kafkaTopic = "iot_data";  // Replace with your topic name

        // Subscribe to 1 topic
        Dataset<Row> df = spark
                .readStream()
                .format("kafka")
                .option("kafka.bootstrap.servers", kafkaBootstrapServers)
                .option("subscribe", kafkaTopic)
                .option("kafkaConsumer.pollTimeoutMs", 120000)
                .load();

        // Parse JSON data
        Dataset<Row> parsedMessages = df.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)")
                .select(
                        functions.col("key"),
                        functions.get_json_object(functions.col("value"), "$.timestamp").as("timestamp"),
                        functions.get_json_object(functions.col("value"), "$.sensor_id").as("sensor_id"),
                        functions.get_json_object(functions.col("value"), "$.temperature").cast("double").as("temperature"),
                        functions.get_json_object(functions.col("value"), "$.humidity").cast("double").as("humidity"),
                        functions.get_json_object(functions.col("value"), "$.pressure").cast("double").as("pressure"),
                        functions.get_json_object(functions.col("value"), "$.aqi").cast("double").as("aqi")
                )
                .withColumn("timestamp", functions.to_timestamp(functions.col("timestamp"), "yyyy-MM-dd'T'HH:mm:ss'Z'")) // Convert timestamp back to timestamp format
                .withWatermark("timestamp", "2 minutes"); // Add watermark with a 2-minute delay (late date destined for earlier window)

        // Aggregate data: calculate the average values per sensor_id over a 2-minute window, sliding every 1 minute
        Dataset<Row> aggregatedData = parsedMessages
                // Group the data into 2-minute windows, with the windows sliding every 1 minute. Within each 2-minute window, group the data by sensor_id
                .groupBy(
                        functions.window(functions.col("timestamp"), "2 minutes", "1 minute"),
                        functions.col("sensor_id")
                )
                // Create columns for averages
                .agg(
                        functions.avg("temperature").as("avg_temperature"),
                        functions.avg("humidity").as("avg_humidity"),
                        functions.avg("pressure").as("avg_pressure"),
                        functions.avg("aqi").as("avg_aqi")
                )
                // Separate window column generated by functions.window into new window_start and window_end columns.
                .withColumn("window_start", functions.col("window").getField("start"))
                .withColumn("window_end", functions.col("window").getField("end"))
                .drop("window"); // Drop old combined window column

        // Output the processed data to console
        StreamingQuery query = null;
        try {
            query = aggregatedData
                    .writeStream()
                    .format("console")
                    .outputMode("update")
                    .start();

            query.awaitTermination();
        } catch (StreamingQueryException e) {
            e.printStackTrace();
        } catch (TimeoutException e) {
            e.printStackTrace();
        }
    }
}
